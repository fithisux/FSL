<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<title>SIENA/UserGuide</title>
<link rel="stylesheet" type="text/css" media="all" charset="utf-8" href="fsl/css/common.css">
<link rel="stylesheet" type="text/css" media="screen" charset="utf-8" href="fsl/css/screen.css">
<link rel="stylesheet" type="text/css" media="print" charset="utf-8" href="fsl/css/print.css">
<style type="text/css">
ul.pagetitle{
  display: inline;
  margin: 0;
  padding: 0;
  font-size: 1.5em;
}
li.pagetitle{
  display: inline;
  margin: 0;
}
td.noborder {
  border: 0;
}
</style>
</head>
<body>
<table>
<tr>
<td class="noborder">
<img src="logo.png">
</td>
<td class="noborder">
<ul class="pagetitle">
<li class="pagetitle"><a class="backlink">SIENA/UserGuide</a>
</ul>
<br><br>
[<a href="FSL.html">FSL</a>]&nbsp;[<a href="TitleIndex.html">TitleIndex</a>]&nbsp;[<a href="WordIndex.html">WordIndex</a>]&nbsp;
</td>
</tr>
</table>
<hr>
<div id="page">
<div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
<span class="anchor" id="line-1"></span><span class="anchor" id="line-2"></span><p class="line867"><div class="FslToolContents">
<h1>Contents</h1>
<ol><li><a href="./SIENA.html">Introduction</a></li><li>User Guide<div class="contentslist"><div class="table-of-contents"><p class="table-of-contents-heading">Contents<ol><li>
<a href="#FSL_Tools_used">FSL Tools used</a></li><li>
<a href="#SIENA_-_Two-Time-Point_Estimation">SIENA - Two-Time-Point Estimation</a><ol><li>
<a href="#Usage">Usage</a></li><li>
<a href="#What_the_script_does">What the script does</a></li><li>
<a href="#Ventricular_extension_-_VIENA">Ventricular extension - VIENA</a></li></ol></li><li>
<a href="#SIENAX_-_Single-Time-Point_Estimation">SIENAX - Single-Time-Point Estimation</a><ol><li>
<a href="#Usage-1">Usage</a></li><li>
<a href="#What_the_script_does-1">What the script does</a></li></ol></li><li>
<a href="#Voxelwise_SIENA_Statistics">Voxelwise SIENA Statistics</a></li></ol></div></div></li><li><a href="./SIENA(2f)FAQ.html">FAQ</a></li></ol></div> <span class="anchor" id="line-3"></span>
<h1 id="FSL_Tools_used">FSL Tools used</h1>
<span class="anchor" id="line-4"></span><span class="anchor" id="line-5"></span><p class="line874">This section lists the generic FSL programs that SIENA uses. <span class="anchor" id="line-6"></span><a href="./BET.html">bet</a> - Brain Extraction Tool. This automatically removes all non-brain tissue from the image. It can optionally output the binary brain mask that was derived during this process, and output an estimate of the external surface of the skull, for use as a scaling constraint in later registration. <span class="anchor" id="line-7"></span><span class="anchor" id="line-8"></span><p class="line867"><tt class="backtick">pairreg</tt>, a script supplied with <a href="./FLIRT.html">FLIRT</a> - FMRIB's Linear Image Registration Tool. This script calls FLIRT with a special optimisation schedule, to register two brain images whilst at the same time using two skull images to hold the scaling constant (in case the brain has shrunk over time, or the scanner calibration has changed). The script first calls FLIRT to register the brains as fully as possible. This registration is then applied to the skull images, but only the scaling and skew are allowed to change. This is then applied to the brain images, and a final pass optimally rotates and translates the brains to get the best final registration. <span class="anchor" id="line-9"></span><span class="anchor" id="line-10"></span><p class="line867"><a href="./FAST.html">fast</a> - FMRIB's Automated Segmentation Tool. This program automatically segments a brain-only image into different tissue types (normally background, grey matter, white matter, CSF and other). It also corrects for bias field. It is used in various ways in the SIENA scripts. Note that both <tt class="backtick">siena</tt> and <tt class="backtick">sienax</tt> allow you to choose between segmentation of grey matter and white matter as separate classes or a single class. It is important to choose the right option here, depending on whether there is or is not reasonable grey-white contrast in the image. <span class="anchor" id="line-11"></span><hr /><p class="line874"> <span class="anchor" id="line-12"></span><br>
 <span class="anchor" id="line-13"></span>
<h1 id="SIENA_-_Two-Time-Point_Estimation">SIENA - Two-Time-Point Estimation</h1>
<span class="anchor" id="line-14"></span><span class="anchor" id="line-15"></span><p class="line867">
<h2 id="Usage">Usage</h2>
<span class="anchor" id="line-16"></span><span class="anchor" id="line-17"></span><p class="line874">A default SIENA analysis is run by typing: <span class="anchor" id="line-18"></span><span class="anchor" id="line-19"></span><p class="line867"><tt class="backtick">siena&nbsp;&lt;input1&gt;&nbsp;&lt;input2&gt;</tt> <span class="anchor" id="line-20"></span><span class="anchor" id="line-21"></span><p class="line874">The input filenames must not contain directory names - i.e. all must be done within a single directory. <span class="anchor" id="line-22"></span><span class="anchor" id="line-23"></span><p class="line874">Other options are: <span class="anchor" id="line-24"></span><span class="anchor" id="line-25"></span><p class="line867"><tt class="backtick">-o&nbsp;&lt;output-dir&gt;</tt> : set output directory (the default output is &lt;input1&gt;_to_&lt;input2&gt;_siena) <span class="anchor" id="line-26"></span><span class="anchor" id="line-27"></span><p class="line867"><tt class="backtick">-d</tt> : debug (don't delete intermediate files) <span class="anchor" id="line-28"></span><span class="anchor" id="line-29"></span><p class="line867"><tt class="backtick">-B&nbsp;"bet&nbsp;options"</tt> : if you want to change the BET defaults, put BET options inside double-quotes after using the -B flag. For example, to increase the size of brain estimation, use: <tt class="backtick">-B&nbsp;"-f&nbsp;0.3"</tt> <span class="anchor" id="line-30"></span><span class="anchor" id="line-31"></span><p class="line867"><tt class="backtick">-2</tt> : two-class segmentation (don't segment grey and white matter separately) - use this if there is poor grey/white contrast <span class="anchor" id="line-32"></span><span class="anchor" id="line-33"></span><p class="line867"><tt class="backtick">-t2</tt>: tell FAST that the input images are T2-weighted and not T1 <span class="anchor" id="line-34"></span><span class="anchor" id="line-35"></span><p class="line867"><tt class="backtick">-m</tt> : use standard-space masking as well as BET (e.g. if it is proving hard to get reliable brain segmentation from BET, for example if eyes are hard to segment out) - register to standard space in order to use a pre-defined standard-space brain mask <span class="anchor" id="line-36"></span><span class="anchor" id="line-37"></span><p class="line867"><tt class="backtick">-t&nbsp;&lt;t&gt;</tt>: ignore from t (mm) upwards in MNI152/Talairach space - if you need to ignore the top part of the head (e.g. if some subjects have the top missing and you need consistency across subjects) <span class="anchor" id="line-38"></span><span class="anchor" id="line-39"></span><p class="line867"><tt class="backtick">-b&nbsp;&lt;b&gt;</tt>: ignore from b (mm) downwards in MNI152/Talairach space; b should probably be -ve <span class="anchor" id="line-40"></span><span class="anchor" id="line-41"></span><p class="line867"><tt class="backtick">-S&nbsp;"siena_diff&nbsp;options"</tt> : if you want to send options to the siena_diff program (that estimates change between two aligned images), put these options in double-quotes after the -S flag. For example, to tell siena_diff to run FAST segmentation with an increased number of iterations, use <tt class="backtick">-S&nbsp;"-s&nbsp;-i&nbsp;20"</tt> <span class="anchor" id="line-42"></span><span class="anchor" id="line-43"></span><p class="line867"><tt class="backtick">-V&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;run&nbsp;ventricle&nbsp;analysis</tt> <a href="./SIENA(2f)UserGuide.html#Ventricular_extension_-_VIENA">VIENA</a> <span class="anchor" id="line-44"></span><span class="anchor" id="line-45"></span><p class="line867"><tt class="backtick">-v&nbsp;&lt;mask&nbsp;image&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;optional&nbsp;user-supplied&nbsp;ventricle&nbsp;mask&nbsp;(default&nbsp;is&nbsp;$FSLDIR/bin/MNI152_T1_2mm_VentricleMask)</tt> <span class="anchor" id="line-46"></span><span class="anchor" id="line-47"></span><p class="line867">
<h2 id="What_the_script_does">What the script does</h2>
<span class="anchor" id="line-48"></span><span class="anchor" id="line-49"></span><p class="line867"><tt class="backtick">siena</tt> carries out the following steps: <span class="anchor" id="line-50"></span><span class="anchor" id="line-51"></span><p class="line862">Run <tt class="backtick">bet</tt> on the two input images, producing as output, for each input: extracted brain, binary brain mask and skull image. If you need to call BET with a different threshold than the default of 0.5, use <tt class="backtick">-f&nbsp;&lt;threshold&gt;</tt>. <span class="anchor" id="line-52"></span><span class="anchor" id="line-53"></span><p class="line862">Run <tt class="backtick">siena_flirt</tt>, a separate script, to register the two brain images. This first calls the FLIRT-based registration script <tt class="backtick">pairreg</tt> (which uses the brain and skull images to carry out constrained registration). It then deconstructs the final transform into two half-way transforms which take the two brain images into a space halfway between the two, so that they both suffer the same amount of interpolation-related blurring. Finally the script produces a multi-slice gif picture showing the registration quality, with one transformed image as the background and edges from the other transformed image superimposed in red. <span class="anchor" id="line-54"></span><span class="anchor" id="line-55"></span><p class="line862">The final step is to carry out change analysis on the registered brain images. This is done using the program <tt class="backtick">siena_diff</tt>. (In order to improve slightly the accuracy of the <tt class="backtick">siena_diff</tt> program, a self-calibration script <tt class="backtick">siena_cal</tt>, described later, is run before this.) <tt class="backtick">siena_diff</tt> carries out the following steps: <span class="anchor" id="line-56"></span><span class="anchor" id="line-57"></span><ul><li>Transforms original whole head images and brain masks for each time point into the space halfway between them, using the two halfway transforms previously generated. <span class="anchor" id="line-58"></span></li><li>Combines the two aligned masks using logical OR (if either is 1 then the output is 1). <span class="anchor" id="line-59"></span></li><li>The combined mask is used to mask the two aligned head images, resulting in aligned brain images. <span class="anchor" id="line-60"></span></li><li><p class="line862">The change between the two aligned brain images is now estimated, using the following method (note that options given to the <tt class="backtick">siena</tt> script are passed on to <tt class="backtick">siena_diff</tt>): Apply tissue segmentation to the first brain image. At all points which are reported as boundaries between brain and non-brain (including internal brain-CSF boundaries), compute the distance that the brain surface has moved between the two time points. This motion of the brain edge (perpendicular to the local edge) is calulated on the basis of sub-voxel correlation (matching) of two 1D vectors; these are taken from the 3D images, a fixed distance either side of the surface point, and perpendicular to it, and are differentiated before correlation, allowing some variation in the two original images. Compute mean perpendicular surface motion and convert to PBVC. <span class="anchor" id="line-61"></span></li><li><p class="line862">To make this conversion between mean perpendicular edge motion and PBVC, it is necessary to assume a certain relationship between real brain surface area, number of estimated edge points and real brain volume. This number can be estimated for general images, but will vary according to slice thickness, image sequence type, etc, causing small scaling errors in the final PBVC. In order to correct for this, self-calibration is applied, in which <tt class="backtick">siena</tt> calls <tt class="backtick">siena_cal</tt>. This script runs <tt class="backtick">siena_diff</tt> on one of the input images relative to a scaled version of itself, with the scaling pre-determined (and therefore known). Thus the final PBVC is known in advance and the estimated value can be compared with this to get a correction factor for the current image. This is done for both input images and the average taken, to give a correction factor to be fed into <tt class="backtick">siena_diff</tt>. <span class="anchor" id="line-62"></span><span class="anchor" id="line-63"></span></li></ul><p class="line874">The files created in the SIENA output directory are: <span class="anchor" id="line-64"></span><span class="anchor" id="line-65"></span><ul><li><p class="line891"><tt class="backtick">report.siena</tt> the SIENA log, including the final PBVC estimate. <span class="anchor" id="line-66"></span></li><li><p class="line891"><tt class="backtick">report.html</tt> a webpage report including images showing various stages of the analysis, the final result and a description of the SIENA method. <span class="anchor" id="line-67"></span></li><li><p class="line891"><tt class="backtick">A_halfwayto_B_render</tt> a colour-rendered image of edge motion superimposed on the halfway A image. Red-yellow means brain volume increase and Blue means brain volume decrease ("atrophy"). <span class="anchor" id="line-68"></span></li><li><p class="line891"><tt class="backtick">A_and_B.gif</tt> a gif image showing the results of the registration, using one transformed image as the background and the other as the coloured edges foreground. <span class="anchor" id="line-69"></span></li><li><p class="line891"><tt class="backtick">A_to_B.mat</tt> the transformation taking A to B, using the brain and skull images. <span class="anchor" id="line-70"></span></li><li><p class="line891"><tt class="backtick">B_to_A.mat</tt> the transformation taking B to A, using the brain and skull images. <span class="anchor" id="line-71"></span></li><li><p class="line891"><tt class="backtick">A_halfwayto_B.mat</tt> and B_halfwayto_A.mat the transformations taking the images to the halfway positions. <span class="anchor" id="line-72"></span><span class="anchor" id="line-73"></span><span class="anchor" id="line-74"></span></li></ul><p class="line867">
<h2 id="Ventricular_extension_-_VIENA">Ventricular extension - VIENA</h2>
<span class="anchor" id="line-75"></span><span class="anchor" id="line-76"></span><ul><li><p class="line862">In FSL5 a ventricular option is introduced that is invoked by the <tt class="backtick">-V</tt> option <span class="anchor" id="line-77"></span></li><li><p class="line862">Outputs can be found in a sub-directory of the siena directory named <tt class="backtick">viena</tt> <span class="anchor" id="line-78"></span></li><li><p class="line862">A separate html report page can be found in the viena directory called <tt class="backtick">reportviena.html</tt> <span class="anchor" id="line-79"></span></li><li>A default ventricle mask (in standard space) is supplied, but users may supply their own if they wish <span class="anchor" id="line-80"></span></li><li>The VIENA extension is provided courtesy of the VU medical center Amsterdam, The Netherlands <span class="anchor" id="line-81"></span><span class="anchor" id="line-82"></span></li></ul><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-83"></span><br>
 <span class="anchor" id="line-84"></span>
<h1 id="SIENAX_-_Single-Time-Point_Estimation">SIENAX - Single-Time-Point Estimation</h1>
<span class="anchor" id="line-85"></span><span class="anchor" id="line-86"></span><p class="line867">
<h2 id="Usage-1">Usage</h2>
<span class="anchor" id="line-87"></span><span class="anchor" id="line-88"></span><p class="line874">A default SIENAX analysis is run by typing: <span class="anchor" id="line-89"></span><span class="anchor" id="line-90"></span><p class="line867"><tt class="backtick">sienax&nbsp;&lt;input&gt;</tt> <span class="anchor" id="line-91"></span><span class="anchor" id="line-92"></span><p class="line874">The input filename must not contain directory names - i.e. all must be done within the current directory. <span class="anchor" id="line-93"></span><span class="anchor" id="line-94"></span><p class="line874">Other options are: <span class="anchor" id="line-95"></span><span class="anchor" id="line-96"></span><p class="line867"><tt class="backtick">-o&nbsp;&lt;output-dir&gt;</tt> : set output directory (the default output is &lt;input&gt;_sienax) <span class="anchor" id="line-97"></span><span class="anchor" id="line-98"></span><p class="line867"><tt class="backtick">-d</tt> : debug (don't delete intermediate files) <span class="anchor" id="line-99"></span><span class="anchor" id="line-100"></span><p class="line867"><tt class="backtick">-B&nbsp;"bet&nbsp;options"</tt> : if you want to change the BET defaults, put BET options inside double-quotes after using the -B flag. For example, to increase the size of brain estimation, use: <tt class="backtick">-B&nbsp;"-f&nbsp;0.3"</tt> <span class="anchor" id="line-101"></span><span class="anchor" id="line-102"></span><p class="line867"><tt class="backtick">-2</tt>: two-class segmentation (don't segment grey and white matter separately) - use this if there is poor grey/white contrast <span class="anchor" id="line-103"></span><span class="anchor" id="line-104"></span><p class="line867"><tt class="backtick">-t2</tt>: tell FAST that the input images are T2-weighted and not T1 <span class="anchor" id="line-105"></span><span class="anchor" id="line-106"></span><p class="line867"><tt class="backtick">-t&nbsp;&lt;t&gt;</tt>: ignore from t (mm) upwards in MNI152/Talairach space - if you need to ignore the top part of the head (e.g. if some subjects have the top missing and you need consistency across subjects) <span class="anchor" id="line-107"></span><span class="anchor" id="line-108"></span><p class="line867"><tt class="backtick">-b&nbsp;&lt;b&gt;</tt>: ignore from b (mm) downwards in MNI152/Talairach space; b should probably be -ve <span class="anchor" id="line-109"></span><span class="anchor" id="line-110"></span><p class="line867"><tt class="backtick">-r</tt>: tell SIENAX to estimate "regional" volumes as well as global; this produces peripheral cortex GM volume (3-class segmentation only) and ventricular CSF volume <span class="anchor" id="line-111"></span><span class="anchor" id="line-112"></span><p class="line867"><tt class="backtick">-lm&nbsp;&lt;mask&gt;</tt>: use a lesion (or lesion+CSF) mask to remove incorrectly labelled "grey matter" voxels <span class="anchor" id="line-113"></span><span class="anchor" id="line-114"></span><p class="line867"><tt class="backtick">-S&nbsp;"FAST&nbsp;options"</tt> : if you want to change the segmentation defaults, put FAST options inside double-quotes after using the -S flag. For example, to increase the number of segmentation iterations use: <tt class="backtick">-S&nbsp;"-i&nbsp;20"</tt> <span class="anchor" id="line-115"></span><span class="anchor" id="line-116"></span><p class="line867">
<h2 id="What_the_script_does-1">What the script does</h2>
<span class="anchor" id="line-117"></span><span class="anchor" id="line-118"></span><p class="line874">sienax carries out the following steps: <span class="anchor" id="line-119"></span><span class="anchor" id="line-120"></span><ul><li><p class="line862">Run <tt class="backtick">bet</tt> on the single input image, outputting the extracted brain, and the skull image. If you need to call BET with a different threshold than the default of 0.5, use <tt class="backtick">-f&nbsp;&lt;threshold&gt;</tt>. <span class="anchor" id="line-121"></span></li><li><p class="line862">Run <tt class="backtick">pairreg&nbsp;</tt>(which uses the brain and skull images to carry out constrained registration); the MNI152 standard brain is the target (reference), using brain and skull images derived from the MNI152. Thus, as with two-time-point atrophy, the brain is registered (this time to the standard brain), again using the skull as the scaling constraint. Thus brain tissue volume (estimated below) will be relative to a "normalised" skull size. (Ignore the "WARNING: had difficulty finding robust limits in histogram" message; this appears because FLIRT isn't too happy with the unusual histograms of skull images, but is nothing to worry about in this context.) Note that all later steps are in fact carried out on the original (but stripped) input image, not the registered input image; this is so that the original image does not need to be resampled (which introduces blurring). Instead, to make use of the normalisation described above, the brain volume (estimated by the segmentation step described below) is scaled by a scaling factor derived from the normalising transform, before being reported as the final normalised brain volume. <span class="anchor" id="line-122"></span></li><li>A standard brain image mask, (derived from the MNI152 and slightly dilated) is transformed into the original image space (by inverting the normalising transform found above) and applied to the brain image. This helps ensure that the original brain extraction does not include artefacts such as eyeballs. <span class="anchor" id="line-123"></span></li><li><p class="line862">Segmentation is now run on the masked brain using <tt class="backtick">fast</tt>. If there is reasonable grey-white contrast, grey matter and white matter volumes are reported separately, as well as total brain volume (this is the default behaviour). Otherwise (i.e. if <tt class="backtick">sienax</tt> was called with the <tt class="backtick">-2</tt> option), just brain/CSF/background segmentation is carried out, and only brain volume is reported. Before reporting, all volumes are scaled by the normalising scaling factor, as described above, so that all subjects' volumes are reported relative to a normalised skull size. <span class="anchor" id="line-124"></span><span class="anchor" id="line-125"></span></li></ul><p class="line874">The main files created in the SIENAX output directory are: <span class="anchor" id="line-126"></span><ul><li><p class="line891"><tt class="backtick">report.sienax</tt> the SIENAX log, including the final volume estimates. <span class="anchor" id="line-127"></span></li><li><p class="line891"><tt class="backtick">report.html</tt> a webpage report including images showing various stages of the analysis, the final result and a description of the SIENAX method. <span class="anchor" id="line-128"></span></li><li><p class="line891"><tt class="backtick">I_render</tt> a colour-rendered image showing the segmentation output superimposed on top of the original image. <span class="anchor" id="line-129"></span></li></ul><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-130"></span>
<h1 id="Voxelwise_SIENA_Statistics">Voxelwise SIENA Statistics</h1>
<span class="anchor" id="line-131"></span><span class="anchor" id="line-132"></span><p class="line874">We have extended SIENA to allow the voxelwise statistical analysis of atrophy across subjects. This takes a SIENA-derived edge "flow image" (edge displacement between the timepoints) for each subject, warps these to align with a standard-space edge image and then carries out voxelwise cross-subject statistical analysis to identify brain edge points which, for example, are signficantly atrophic for the group of subjects as a whole, or where atrophy correlates significantly with age or disease progression. <span class="anchor" id="line-133"></span><span class="anchor" id="line-134"></span><p class="line874">In order to carry out voxelwise SIENA statistics, do the following: <span class="anchor" id="line-135"></span><span class="anchor" id="line-136"></span><ul><li>Run  <span class="anchor" id="line-137"></span><p class="line891"><tt class="backtick">&nbsp;siena&nbsp;A&nbsp;B&nbsp;</tt><br>
 <span class="anchor" id="line-138"></span>on all subjects' two-timepoints data (here A and B). <span class="anchor" id="line-139"></span></li><li>For each subject run  <span class="anchor" id="line-140"></span><p class="line891"><tt class="backtick">cd&nbsp;&lt;siena_output_directory&gt;</tt><br>
 <span class="anchor" id="line-141"></span><tt class="backtick">siena_flow2std&nbsp;A&nbsp;B</tt><br>
 <span class="anchor" id="line-142"></span>this runs flirt to generate the transform to standard space (if it doesn't already exist), takes the edge      flow (atrophy) image generated by <tt class="backtick">siena</tt>, dilates this several times (to "thicken" this edge flow image), transforms to standard space, and masks with a standard space edge mask. It then smooths this with a default Gaussian filter of half-width 5mm before remasking. If you want to change the smoothing then use the -s option; set the smoothing to zero to turn if off completely. <span class="anchor" id="line-143"></span></li><li><p class="line862">All subjects will now have an edge flow image in standard edge space called <tt class="backtick">A_to_B_flow_to_std</tt>. Merge these into a single 4D image; for example, if each subject's analysis has so far been carried out in a subdirectory called subject_*/A_to_B_siena, where the * could be subject ID or name, use a command such as: <span class="anchor" id="line-144"></span><tt>fslmerge&nbsp;-t&nbsp;flow_all_subjects&nbsp;`imglob&nbsp;subject_*/A_to_B_siena/A_to_B_flow_to_std*</tt><br>
 <span class="anchor" id="line-145"></span>Note: it is very important that the order that the subjects appear in this command matches the order you intend when you then create the design matrix! <span class="anchor" id="line-146"></span></li><li><p class="line862">You are now ready to carry out the cross-subject statistics. We recommend using <a href="./Randomise.html">randomise</a> for this, as the above steps are very unlikely to generate nice Gaussian distributions in the data. You will need to generate a FEAT-style design matrix design.mat and contrasts file design.con. The mask image that you use for randomise should be <tt class="backtick">${FSLDIR}/data/standard/MNI152_T1_2mm_edges</tt> <span class="anchor" id="line-147"></span></li></ul><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-148"></span><a href="./CategorySIENA.html">CategorySIENA</a> <span class="anchor" id="line-149"></span><span class="anchor" id="bottom"></span></div>
</div>
<hr>
2014-07-08 15:34
</body>
</html>
