<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<title>GLM</title>
<link rel="stylesheet" type="text/css" media="all" charset="utf-8" href="fsl/css/common.css">
<link rel="stylesheet" type="text/css" media="screen" charset="utf-8" href="fsl/css/screen.css">
<link rel="stylesheet" type="text/css" media="print" charset="utf-8" href="fsl/css/print.css">
<style type="text/css">
ul.pagetitle{
  display: inline;
  margin: 0;
  padding: 0;
  font-size: 1.5em;
}
li.pagetitle{
  display: inline;
  margin: 0;
}
td.noborder {
  border: 0;
}
</style>
</head>
<body>
<table>
<tr>
<td class="noborder">
<img src="logo.png">
</td>
<td class="noborder">
<ul class="pagetitle">
<li class="pagetitle"><a class="backlink">GLM</a>
</ul>
<br><br>
[<a href="FSL.html">FSL</a>]&nbsp;[<a href="TitleIndex.html">TitleIndex</a>]&nbsp;[<a href="WordIndex.html">WordIndex</a>]&nbsp;
</td>
</tr>
</table>
<hr>
<div id="page">
<div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
<span class="anchor" id="line-1"></span><p class="line867"><div class="FslToolContents">
<h1>Contents</h1>
<ol><li>Introduction<div class="contentslist"><div class="table-of-contents"><p class="table-of-contents-heading">Contents<ol><li>
<a href="#Experimental_Designs_-_No_repeated_measures">Experimental Designs - No repeated measures</a><ol><li>
<a href="#Single-Group_Average_.28One-Sample_T-Test.29">Single-Group Average (One-Sample T-Test)</a><ol><li>
<a href="#FEAT_details">FEAT details</a></li><li>
<a href="#Randomise_details">Randomise details</a></li></ol></li><li>
<a href="#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29">Two-Group Difference (Two-Sample Unpaired T-Test)</a><ol><li>
<a href="#FEAT_details-1">FEAT details</a></li><li>
<a href="#Randomise_details-1">Randomise details</a></li></ol></li><li>
<a href="#Singleton-vs-Group_.28Prediction_Interval_Test.29">Singleton-vs-Group (Prediction Interval Test)</a><ol><li>
<a href="#FEAT_details-2">FEAT details</a></li><li>
<a href="#Randomise_details-2">Randomise details</a></li></ol></li><li>
<a href="#F-Tests_.28Inter-Group_differences.2C_no_repeated_measures.29">F-Tests (Inter-Group differences, no repeated measures)</a><ol><li>
<a href="#FEAT_details-3">FEAT details</a></li><li>
<a href="#Randomise_details-3">Randomise details</a></li></ol></li><li>
<a href="#Single-Group_Average_with_Additional_Covariate">Single-Group Average with Additional Covariate</a><ol><li>
<a href="#FEAT_details-4">FEAT details</a></li><li>
<a href="#Randomise_details-4">Randomise details</a></li></ol></li><li>
<a href="#Two-Group_Difference_Adjusted_for_Covariate">Two-Group Difference Adjusted for Covariate</a><ol><li>
<a href="#FEAT_details-5">FEAT details</a></li><li>
<a href="#Randomise_details-5">Randomise details</a></li></ol></li><li>
<a href="#Two_Groups_with_continuous_covariate_interaction">Two Groups with continuous covariate interaction</a><ol><li>
<a href="#FEAT_details-6">FEAT details</a></li><li>
<a href="#Randomise_details-6">Randomise details</a></li></ol></li></ol></li><li>
<a href="#Experimental_Designs_-_Between_Subject_ANOVA_Models">Experimental Designs - Between Subject ANOVA Models</a><ol><li>
<a href="#ANOVA:_1-factor_4-levels__.281-way_between-subjects_ANOVA.29">ANOVA: 1-factor 4-levels  (1-way between-subjects ANOVA)</a><ol><li>
<a href="#FEAT_details-7">FEAT details</a></li><li>
<a href="#Randomise_details-7">Randomise details</a></li></ol></li><li>
<a href="#ANOVA:_2-factors_2-levels_.282-way_between-subjects_ANOVA.29">ANOVA: 2-factors 2-levels (2-way between-subjects ANOVA)</a><ol><li>
<a href="#FEAT_details-8">FEAT details</a></li><li>
<a href="#Randomise_details-8">Randomise details</a></li></ol></li><li>
<a href="#ANOVA:_2-factors_2-_.26_3-levels_.282x3_between-subjects_ANOVA.29">ANOVA: 2-factors 2- &amp; 3-levels (2x3 between-subjects ANOVA)</a><ol><li>
<a href="#FEAT_details-9">FEAT details</a></li><li>
<a href="#Randomise_details-9">Randomise details</a></li></ol></li><li>
<a href="#ANOVA:_3-factors_2-levels_.283-way_between-subjects_ANOVA.29">ANOVA: 3-factors 2-levels (3-way between-subjects ANOVA)</a><ol><li>
<a href="#FEAT_details-10">FEAT details</a></li><li>
<a href="#Randomise_details-10">Randomise details</a></li></ol></li></ol></li><li>
<a href="#Experimental_Designs_-_Repeated_measures">Experimental Designs - Repeated measures</a><ol><li>
<a href="#Single-Group_Paired_Difference_.28Paired_T-Test.29">Single-Group Paired Difference (Paired T-Test)</a><ol><li>
<a href="#FEAT_details-11">FEAT details</a></li><li>
<a href="#Randomise_details-11">Randomise details</a></li></ol></li><li>
<a href="#Single-Group.2C_Three_Measurements_.28.22Tripled_T-Test.22.29">Single-Group, Three Measurements ("Tripled T-Test")</a><ol><li>
<a href="#FEAT_details-12">FEAT details</a></li><li>
<a href="#Randomise_details-12">Randomise details</a></li></ol></li><li>
<a href="#Multi-Session_.26_Multi-Subject_.28Repeated_Measures_-_Three_Level_Analysis.29">Multi-Session &amp; Multi-Subject (Repeated Measures - Three Level Analysis)</a><ol><li>
<a href="#FEAT_details-13">FEAT details</a></li><li>
<a href="#Randomise_details-13">Randomise details</a></li></ol></li><li>
<a href="#ANOVA:_2-groups.2C_2-levels_per_subject_.282-way_Mixed_Effect_ANOVA.29">ANOVA: 2-groups, 2-levels per subject (2-way Mixed Effect ANOVA)</a><ol><li>
<a href="#FEAT_details-14">FEAT details</a></li><li>
<a href="#Randomise_details-14">Randomise details</a></li></ol></li></ol></li></ol></div></div></li><li><a href="./GLM(2f)Faq.html">FAQ</a></li></ol></div> <span class="anchor" id="line-2"></span><span class="anchor" id="line-3"></span><p class="line867"><strong>Introduction</strong> <span class="anchor" id="line-4"></span><span class="anchor" id="line-5"></span><p class="line862">This GLM page attempts to be a cookery book for all common multi-subject designs encountered by FSL users, with details on how to run the design both in FEAT (for higher-level fMRI) and randomise (everything, including higher-level fMRI).   The foundation of statistical modelling in FSL is the general linear model (GLM), where the response <em>Y</em> at each voxel is modeled as a linear combination of one or more predictors, stored in the columns of a "design matrix" <em>X</em>.  Instead of directly specifying experimental designs (e.g. "Two-Sample t-test, 1 group of 5, one group of 8"), in FSL it is left up to the user to craft the matrix <em>X</em> that corresponds the experimental design and other effects to be modelled.   This is not a task to be taken lightly, and it is easy to create meaningless design matrices.  The notes below cannot be a substitute for study in statistical modelling, the GLM and (closely related) the general linear hypothesis. One recommended text book is "Applied Linear Statistical Models" (4th Edition or later), by Neter, Kutner, Wasserman and Nachtsheim; those with a more mathematical background may prefer "Plane Answers to Complex Questions" by Christensen. <span class="anchor" id="line-6"></span><span class="anchor" id="line-7"></span><p class="line862">This is a work in progress - check back for more examples and more details on how the different rules do or don't apply across the different individual programs.  Many thanks to Jeanette Mumford and Tom Nichols for much work on this page (and credit to Jeanette's <a class="attachment" href="attachments/GLM/JMglm.pdf" title="intro slides on various GLM/ANOVA examples">intro slides on various GLM/ANOVA examples</a> that served as inspiration). <span class="anchor" id="line-8"></span><span class="anchor" id="line-9"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-10"></span>
<h1 id="Experimental_Designs_-_No_repeated_measures">Experimental Designs - No repeated measures</h1>
<span class="anchor" id="line-11"></span><p class="line874">We start considering only designs where there is one scan per subject, that is, no repeated measures. <span class="anchor" id="line-12"></span><span class="anchor" id="line-13"></span><p class="line867">
<h2 id="Single-Group_Average_.28One-Sample_T-Test.29">Single-Group Average (One-Sample T-Test)</h2>
<span class="anchor" id="line-14"></span><p class="line862">This is the simplest possible linear model, where a single, homogeneous group of subjects is modelled, and the mean response is tested to see if it is different from zero.  This model is <em>not</em> appropriate for first-level fMRI or other data (e.g., FA values or FIRST vertex analysis), where the mean of the data is not of interest (e.g. consider the mean FA of a single group; testing mean(FA)&gt;0 is pointless, as FA must be positive).  This model <em>is</em> appropriate for higher-level fMRI data. <span class="anchor" id="line-15"></span><span class="anchor" id="line-16"></span><p class="line867">
<h3 id="FEAT_details">FEAT details</h3>
<span class="anchor" id="line-17"></span><p class="line862">To get the most out of FEAT, be sure to have selected "Higher-level analysis" and input the lower-level FEAT directories.  We have 8 subjects all in one group and want the mean group effect. Significance on contrast C1 is evidence for a positive effect, mean &gt; 0. <span class="anchor" id="line-18"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg1.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-19"></span><span class="anchor" id="line-20"></span><span class="anchor" id="line-21"></span><span class="anchor" id="line-22"></span><span class="anchor" id="line-23"></span><p class="line867">
<h3 id="Randomise_details">Randomise details</h3>
<span class="anchor" id="line-24"></span><p class="line862">Strictly speaking, a one-sample permutation test is impossible.  Traditionally, a permutation test swaps labels between two groups of subjects (here impossible, as there is only one group) or shuffles the values of a covariate (the covariate is a column of ones, unaltered by permutation).  Only with an assumption of independent symmetric errors can a specialised test be performed, where, instead of permuting the data, each subject's data is multiplied by either +1 or -1.  Thus there are 2<sup>N</sup> possible sign flips.  This assumption is justified by the data consisting of differences where, under the null hypothesis, the subtracted data has the same distribution; equivalently, the data can be a COPE from a GLM and then the assumption is simply that the GLM errors are centered on zero and symmetrically distributed. <span class="anchor" id="line-25"></span><span class="anchor" id="line-26"></span><p class="line862">Use the <tt class="backtick">-1</tt> option with randomise to indicate a one-sample t-test; see <a class="http" href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide#One-Sample_T-test">Randomise examples</a> for more.  Significance for this test will indicate a positive effect, mean &gt; 0.  To obtain the negative effect, first multiply the original data used to test the positive mean (input_data) by -1 using: fslmaths input_data.nii.gz -mul -1 neg_input_data.nii.gz and then use neg_input_data.nii.gz in randomise.  In the example illustrated above, there are 8 subjects, and thus 2<sup>8</sup> = 256 possible permutations, and the smallest possible permutation P-value 1/256 = 0.0039. <span class="anchor" id="line-27"></span><span class="anchor" id="line-28"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-29"></span><span class="anchor" id="line-30"></span><p class="line867">
<h2 id="Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29">Two-Group Difference (Two-Sample Unpaired T-Test)</h2>
<span class="anchor" id="line-31"></span><p class="line862">The purpose of this model is to test whether the means of two groups differ.  Significance of C1 indicates that mean(G1)&gt;mean(G2), or the first group's mean is larger than the second.  Similarly, significance of C2 indicates mean(G2)&lt;mean(G1). <span class="anchor" id="line-32"></span><span class="anchor" id="line-33"></span><p class="line867">
<h3 id="FEAT_details-1">FEAT details</h3>
<span class="anchor" id="line-34"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_sample_t.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-35"></span><span class="anchor" id="line-36"></span><span class="anchor" id="line-37"></span><p class="line867">
<h3 id="Randomise_details-1">Randomise details</h3>
<span class="anchor" id="line-38"></span><p class="line862">Use the same design matrix and contrasts as shown in the Feat details.  There are (n<sub>1</sub>+n<sub>2</sub>)-choose-n<sub>1</sub> = (n<sub>1</sub>+n<sub>2</sub>)! / (n<sub>1</sub>! n<sub>2</sub>!) possible permutations; here that is 8-choose-4 = 70 possible permutations and the smallest possible permutation P-value is 1/70 = 0.0143, and the largest possible below 0.05 is 0.0429. <span class="anchor" id="line-39"></span><span class="anchor" id="line-40"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-41"></span><span class="anchor" id="line-42"></span><p class="line867">
<h2 id="Singleton-vs-Group_.28Prediction_Interval_Test.29">Singleton-vs-Group (Prediction Interval Test)</h2>
<span class="anchor" id="line-43"></span><p class="line874">This model is basically a special case of the previous model, when one group has exactly one subject in it.  It typically is used to compare a patient against a group of controls. <span class="anchor" id="line-44"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="&lt;!&gt;" height="15" src="/fsl/wiki_static/fsl/img/attention.png" title="&lt;!&gt;" width="15" /> Warning!  This type of model is notoriously sensitive to the Normality assumptions of standard parametric tests. Usually, we can be happy in the knowledge that, as we have more and more data, our test statistics will be better-and-better behaved (i.e. they become more Normally distributed if they weren't in the first place).  For the two-group case, it turns out that it is the smaller of the two sample sizes that matter, and in the Singleton-vs-Group case, this means <em>no</em> amount large sample size can eliminate non-Normality problems.  This of course motivates the use of nonparametric inference with randomise, but read below for the problem with that solution. </td>
</tr>
</tbody></table></div><span class="anchor" id="line-45"></span><span class="anchor" id="line-46"></span><span class="anchor" id="line-47"></span><span class="anchor" id="line-48"></span><span class="anchor" id="line-49"></span><p class="line867">
<h3 id="FEAT_details-2">FEAT details</h3>
<span class="anchor" id="line-50"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/single_vs_group.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-51"></span><span class="anchor" id="line-52"></span><span class="anchor" id="line-53"></span><p class="line867">
<h3 id="Randomise_details-2">Randomise details</h3>
<span class="anchor" id="line-54"></span><p class="line862">Use the same design matrix and contrasts as shown in the Feat details.  There are (n+1)-choose-n = n+1 possible permutations; here that is 7+1 = 8 possible permutations and the smallest possible permutation P-value is 1/8 = 0.1250.  This is of course is a problem... in this situation when we <em>most</em> need a nonparametric procedure with weak assumptions, we are probably unable to use it because insufficient permutations. <span class="anchor" id="line-55"></span><span class="anchor" id="line-56"></span><p class="line862">Recall that <em>any</em> number of permutations produces a valid test, so even if you have only 19+1 = 20 subjects, it may be worth trying, but P-values will be highly discrete. <span class="anchor" id="line-57"></span><span class="anchor" id="line-58"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-59"></span><span class="anchor" id="line-60"></span><p class="line867">
<h2 id="F-Tests_.28Inter-Group_differences.2C_no_repeated_measures.29">F-Tests (Inter-Group differences, no repeated measures)</h2>
<span class="anchor" id="line-61"></span><p class="line867">
<h3 id="FEAT_details-3">FEAT details</h3>
<span class="anchor" id="line-62"></span><p class="line874">For example, three groups of subjects, with the question - do the group averages account some significant effect?  Typically when an F-test is significant, individual t-tests are then used to determine the direction of the effect. <span class="anchor" id="line-63"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/f_test.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-64"></span><span class="anchor" id="line-65"></span><span class="anchor" id="line-66"></span><span class="anchor" id="line-67"></span><span class="anchor" id="line-68"></span><p class="line867">
<h3 id="Randomise_details-3">Randomise details</h3>
<span class="anchor" id="line-69"></span><p class="line862">F-tests in randomise require the additional design.fts file, which can be generated for you by constructing the above design using the <tt class="backtick">Glm_gui</tt>.  The randomise call (using TFCE) would be the following: <span class="anchor" id="line-70"></span><span class="anchor" id="line-71"></span><p class="line867"><span class="anchor" id="line-72"></span><span class="anchor" id="line-73"></span><pre><span class="anchor" id="line-1"></span>randomise -i &lt;4D_input_data&gt; -o &lt;output_rootname&gt; -d &lt;design.mat&gt; -t &lt;design.con&gt; -f &lt;design.fts&gt; -m &lt;mask_image&gt; -n 500 -T</pre><span class="anchor" id="line-74"></span><p class="line862">The number of possible permutations in this design is determined by the multinomial coefficient, (n<sub>1</sub>+n<sub>2</sub>+n<sub>3</sub>)! / ( n<sub>1</sub>! n<sub>2</sub>! n<sub>3</sub>! ).  For this design, this is 756,756 possible permutations.  Of course, it is not necessary to run all of these permutations, and a <a class="http" href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/Theory#Monte_Carlo_Permutation_Tests">Monte Carlo permutation test</a>  (i.e. running a random subset of permutations) can be used; in the example above, a random subset of 500 permutations is requested. <span class="anchor" id="line-75"></span><span class="anchor" id="line-76"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-77"></span><span class="anchor" id="line-78"></span><p class="line867">
<h2 id="Single-Group_Average_with_Additional_Covariate">Single-Group Average with Additional Covariate</h2>
<span class="anchor" id="line-79"></span><p class="line867">
<h3 id="FEAT_details-4">FEAT details</h3>
<span class="anchor" id="line-80"></span><p class="line862">We have 7 subjects all in one group. We also have additional measurements such as age, disability scale or behavioural measures such as mean reaction times. The additional effect of the extra measures can be found by entering this as an extra EV, which should be orthogonal wrt the group mean EV - so in this case simply demeaned.  Significance of C1 indicates the mean &gt; 0 and significance of C2 indicates a positive linear relationship (slope) between the behavioural measure and BOLD activation.  If the behavioural measure is not demeaned, C1's interpretation will be the average BOLD activation when the behavioural measure has a value of 0, which often is not interesting. <span class="anchor" id="line-81"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg6.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-82"></span><span class="anchor" id="line-83"></span><span class="anchor" id="line-84"></span><span class="anchor" id="line-85"></span><span class="anchor" id="line-86"></span><p class="line867">
<h3 id="Randomise_details-4">Randomise details</h3>
<span class="anchor" id="line-87"></span><p class="line874">Depending on what version of randomise is used, it may or may not handle the model described under the FEAT details section.  Since the mean activation using randomise was already described above, this section will only cover obtaining inferences for the relationship between the behavioural measure and dependent variable.  The following design matrix and contrast would be used in randomise with the -D option: <span class="anchor" id="line-88"></span><span class="anchor" id="line-89"></span><p class="line867"><span class="anchor" id="line-90"></span><span class="anchor" id="line-91"></span><pre><span class="anchor" id="line-1-1"></span>randomise -i &lt;4D_input_data&gt; -o &lt;output_rootname&gt; -d &lt;design.mat&gt; -t &lt;design.con&gt;  -m &lt;mask_image&gt; -n 500 -T -D</pre><span class="anchor" id="line-92"></span><p class="line874">Note that the behavioural measure is demeaned, although newer versions of randomise (FSL5 or newer) will demean both the data and design with the -D option. <span class="anchor" id="line-93"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/randomise_cont_cov.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-94"></span><span class="anchor" id="line-95"></span><span class="anchor" id="line-96"></span><span class="anchor" id="line-97"></span><span class="anchor" id="line-98"></span><p class="line874">For a test covariate like here, the number of possible permutations is n!.  For this example 7! = 5,040, which should not take very long for such a small dataset.  However, a Monte Carlo test can be used, as indicated above with the -n 500 option. <span class="anchor" id="line-99"></span><span class="anchor" id="line-100"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-101"></span><span class="anchor" id="line-102"></span><p class="line867">
<h2 id="Two-Group_Difference_Adjusted_for_Covariate">Two-Group Difference Adjusted for Covariate</h2>
<span class="anchor" id="line-103"></span><p class="line874">This is an extension of the Two-Group difference.  It is often important to verify that any group differences cannot be explained by some other covariate, e.g. age or reaction time.  In this example there are 10 subjects split between two groups and the inference of interest is whether the group difference remains after adjusting for age.  Additionally, age inferences are also created. <span class="anchor" id="line-104"></span><span class="anchor" id="line-105"></span><p class="line867">
<h3 id="FEAT_details-5">FEAT details</h3>
<span class="anchor" id="line-106"></span><p class="line862">This is exactly the Two-Group Difference model, but with a single new regressor for Age added.  Age is mean centered in this model by <strong>subtracting the overall mean</strong> age from each individual age.  Importantly, this is done <strong>across <em>all</em> subjects and <em>not</em> within group</strong>.  The alternative, within-group mean centering, would remove any ability of age to describe group differences and if that was done the group difference inferences would <em>not</em> be adjusted for age. Consequently, the overall mean is removed here so that the inferences are adjusted for any age differences between the groups. The interpretation of C1 is Group1&gt;Group2, adjusted for age.  Likewise C2 is Group2&gt;Group1, adjusted for age.  C3 is the positive age effect and C4 is the negative age effect.  To adjust for multiple covariates, simply add more EVs to the model, one for each additionally covariate and mean center each covariate.  Even if you add a covariate like Gender, simply add a covariate that is 1 for one gender, 0 for the other and mean center this.  A contrast that pulls out only the Gender covariate tests whether the male/female difference is significant. <span class="anchor" id="line-107"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_group_cont_cov.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-108"></span><span class="anchor" id="line-109"></span><span class="anchor" id="line-110"></span><span class="anchor" id="line-111"></span><span class="anchor" id="line-112"></span><p class="line867">
<h3 id="Randomise_details-5">Randomise details</h3>
<span class="anchor" id="line-113"></span><p class="line874">The above model may also be used with randomise.  The number of permutations possible will depend on the contrast used; a contrast for a group difference will have (n1+n2)-choose-n1 possible permutations, while a contrast for the covariate will have (n1+n2)! possible permutations.  Here that is 252 permutations for the group difference and 3,638,800 permutations for the covariate. <span class="anchor" id="line-114"></span><span class="anchor" id="line-115"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-116"></span><span class="anchor" id="line-117"></span><p class="line867">
<h2 id="Two_Groups_with_continuous_covariate_interaction">Two Groups with continuous covariate interaction</h2>
<span class="anchor" id="line-118"></span><p class="line862">This is an extension of the previous model.  There are again 10 subjects in 2 groups, but in this case the inference of interest is whether the linear relationship between the dependent variable and age differs between the two groups.  Importantly, this model should only be used to interpret the interaction effect.  A test of the difference in group means does not make sense in the presence of a significant interaction, as the interaction indicates that the group difference varies as a function of age.  Therefore, focusing on a single age is not likely all that interesting.  Instead, if the interaction is not significant, the group mean differences can be obtained from the previous model.  For more details on interpreting interactions, please refer to any introductory regression text book.  As mentioned above, "Applied Linear Statistical Models" by Neter <em>et al.</em> is a good reference.  Again, if you run this model and the interaction is not significant anywhere in the brain, use the simpler, Two-Group Difference Adjusted for Covariate, model described above.  If the interaction is significant, only the inferences for the interaction are of interest. <span class="anchor" id="line-119"></span><span class="anchor" id="line-120"></span><p class="line867">
<h3 id="FEAT_details-6">FEAT details</h3>
<span class="anchor" id="line-121"></span><p class="line862">The interaction model splits up the age covariate from the previous model into two EVs.  Again, Age is <strong>mean centered across <em>all</em> subjects</strong> before splitting into two EVs.  Significance of C1 indicates that the slope between your dependent variable and age for Group 1 is larger than that of Group 2.  C2 finds when the slope is larger for Group 2 than Group 2.  Obtaining a better picture of what is happening when there's a significant interaction would require more tests of the individual group slopes. <span class="anchor" id="line-122"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_group_int_cont.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-123"></span><span class="anchor" id="line-124"></span><span class="anchor" id="line-125"></span><span class="anchor" id="line-126"></span><span class="anchor" id="line-127"></span><p class="line867">
<h3 id="Randomise_details-6">Randomise details</h3>
<span class="anchor" id="line-128"></span><p class="line874">The above model may also be used with randomise.  The enumerations of permutations is the same as in the previous example. <span class="anchor" id="line-129"></span><span class="anchor" id="line-130"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-131"></span><hr /><p class="line874"> <span class="anchor" id="line-132"></span><span class="anchor" id="line-133"></span><p class="line867">
<h1 id="Experimental_Designs_-_Between_Subject_ANOVA_Models">Experimental Designs - Between Subject ANOVA Models</h1>
<span class="anchor" id="line-134"></span><p class="line862">The term Analysis of Variance (ANOVA) refers to a number of different concepts, but here use it to describe experimental designs that are based on one or more discrete-valued variables called <em>factors</em>, where the unique values of each factor are called <em>levels</em>.  In this section we only consider between subject models, that is, designs where each subject only contributes a single measurement to the analysis. <span class="anchor" id="line-135"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="{i}" height="16" src="/fsl/wiki_static/fsl/img/icon-info.png" title="{i}" width="16" /> <strong>Statistics Jargon Decoder: Modelling Factors with "Cell means" vs. "Factor effects".</strong>   Modelling factors in a GLM requires the creation of so-called "dummy variables", made up covariates that express discrete-valued factors.  There are literally an infinite number of ways of creating dummy variables to represent a factor, but there are two standard approaches.   For a <em>K</em>-level factor, the "cell means" approach entails creating <em>K</em> dummy variables, one for each level, modelling the "mean" for the "cell" corresponding to that level; the <em>k</em>-th dummy variable has value 1 for observations in <em>k</em>-th level of the factor (1 &lt;= <em>k</em> &lt;= <em>K</em>).  This approach is easy to implement and leads to intuitive contrasts, however the <em>K</em> dummy variables also model the grand mean (or intercept), which can cause trouble if you have more than one factor and lead to rank-deficient design matrices.  The "Factor effects" approach uses <em>K</em>-1 dummy variables to represent a <em>K</em>-level factor, and in particular allows the grand mean to be modelled in another part of the model.  There are different approaches for constructing the <em>K</em>-1 dummy variables, detailed below.  The advantage of the factor effects approach is that the grand mean is not modelled, and thus there is no problem with rank-deficient design matrices.  However, the mapping from <em>K</em> factor levels to the <em>K</em>-1 dummy variables is non-intuitive and thus creating contrasts is not as easy with the cell means approach. The two approaches are equivalent in terms of fit (as long as a GLM using factor effects also includes a grand mean). </td>
</tr>
</tbody></table></div><span class="anchor" id="line-136"></span><span class="anchor" id="line-137"></span><span class="anchor" id="line-138"></span><span class="anchor" id="line-139"></span><span class="anchor" id="line-140"></span><p class="line867">
<h2 id="ANOVA:_1-factor_4-levels__.281-way_between-subjects_ANOVA.29">ANOVA: 1-factor 4-levels  (1-way between-subjects ANOVA)</h2>
<span class="anchor" id="line-141"></span><p class="line867">
<h3 id="FEAT_details-7">FEAT details</h3>
<span class="anchor" id="line-142"></span><p class="line867"><strong>Cell means model.</strong> We have 8 subjects and 1 factor at 4 levels A, B, C and D. The first two inputs are subjects in condition A, the next two are B etc.  While this is the most intuitive approach, as each "cell mean" in the ANOVA (level A, level B, etc.) is directly modelled, the standard ANOVA F-test for any cell mean differences may not seem obvious.  The overall F-test, tests whether mean(A)=mean(B)=mean(C)=mean(D), which is equivalent to mean(A)-mean(D)=mean(B)-mean(D)=mean(C)-mean(D)=0.  In this format it is easy to see that this F-test require simultaneously testing each mean's comparison to mean(D) or the following three contrasts: [ 1 0 0 -1], [0 1 0 -1] and [0 0 1 -1].  This F-test is set up in the GUI as well as the overall mean test, which averages the 4 cells using [0.25 0.25 0.25 0.25]. <span class="anchor" id="line-143"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/one_way_anova_4lev_cell_means.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-144"></span><span class="anchor" id="line-145"></span><span class="anchor" id="line-146"></span><span class="anchor" id="line-147"></span><span class="anchor" id="line-148"></span><p class="line867"><strong>Factor effects model.</strong>  The factor effect dummy variables are less intuitive, but the traditional ANOVA contrasts are easier to construct.  More importantly, factor effects can be used with complicated (i.e. multifactor) ANOVA models (eg. the 3-factor 2-level model below).  When using a factor effects setup, it is essential that your design includes a grand mean or intercept, i.e. a column of 1s. In this example there is one factor with 4 levels and so 3 EVs are necessary to model the factor.  First choose a reference level (in this case we choose A) and for each EV, rows of the design corresponding to A will have a -1.  For each level, construct an EV where the value is: -1 for level A, 1 for the level of interest, and 0 otherwise.  The first EV is -1 for A, 1 for B and 0 for C and D.  Similarly, the second EV is -1 for A, 1 for C and 0 for B and D.  Lastly, the third EV is -1 for A, 1 for D and 0 for B and C.  Last is the column of 1's. <span class="anchor" id="line-149"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/one_way_anova_4lev_factor_eff.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-150"></span><span class="anchor" id="line-151"></span><span class="anchor" id="line-152"></span><span class="anchor" id="line-153"></span><span class="anchor" id="line-154"></span><p class="line874">This seemingly odd construction derives from assuming that the factor levels sum to zero (i.e. mean(A)+mean(B)+mean(C)+mean(D)=0).  Thus while the first 3 EVs may appear to be the comparison of A to each level, actually EVs 1-3 are the comparisons of levels B, C, and D, respectively, to the overall mean.  As stated earlier this model makes it easier to test the standard ANOVA hypotheses.  The main effect for the factor is simply an F-test that combines individual tests for each of the EVs that were constructed for the factor effect (i.e. the first 3 EVs). <span class="anchor" id="line-155"></span><span class="anchor" id="line-156"></span><p class="line874">Obtaining inferences for cell means is not too difficult with this model either and the contrast is actually contained in the design matrix.  If the parameters estimated for this model are PE1, PE2, PE3 and PE4, matrix multiplication of the design with this parameter vector shows that all A-related values are equal to -PE1-PE2-PE3+PE4 and so the contrast to test the mean(A)=0 is [-1 -1 -1 1].  Likewise, the mean(B) corresponds to PE1+PE4 and the contrast is [1 0 0 1].  Lastly the mean(C) would be [0 1 0 1] and mean(D) would be [0 0 1 1]. The following table summarises the contrasts that correspond to each factor level mean. <span class="anchor" id="line-157"></span><div><table><tbody><tr>  <td><p class="line891"><strong>Factor Effect</strong> </td>
  <td><p class="line891"><strong>PE1</strong> </td>
  <td><p class="line891"><strong>PE2</strong> </td>
  <td><p class="line891"><strong>PE3</strong> </td>
  <td><p class="line891"><strong>PE4</strong> </td>
</tr>
<tr>  <td><span class="anchor" id="line-158"></span><p class="line862">mean(A) </td>
  <td><p class="line862">-1 </td>
  <td><p class="line862">-1 </td>
  <td><p class="line862">-1 </td>
  <td><p class="line862">1 </td>
</tr>
<tr>  <td><span class="anchor" id="line-159"></span><p class="line862">mean(B) </td>
  <td><p class="line862">1 </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">1 </td>
</tr>
<tr>  <td><span class="anchor" id="line-160"></span><p class="line862">mean(C) </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">1 </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">1 </td>
</tr>
<tr>  <td><span class="anchor" id="line-161"></span><p class="line862">mean(D) </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">0 </td>
  <td><p class="line862">1 </td>
  <td><p class="line862">1 </td>
</tr>
</tbody></table></div><span class="anchor" id="line-162"></span><span class="anchor" id="line-163"></span><span class="anchor" id="line-164"></span><span class="anchor" id="line-165"></span><span class="anchor" id="line-166"></span><p class="line874">Note that contrasts of individual levels can be made by subtracting the corresponding contrast of PE's. <span class="anchor" id="line-167"></span><span class="anchor" id="line-168"></span><p class="line867">
<h3 id="Randomise_details-7">Randomise details</h3>
<span class="anchor" id="line-169"></span><p class="line874">Either of the above models may also be used with randomise. <span class="anchor" id="line-170"></span><span class="anchor" id="line-171"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-172"></span><span class="anchor" id="line-173"></span><p class="line867">
<h2 id="ANOVA:_2-factors_2-levels_.282-way_between-subjects_ANOVA.29">ANOVA: 2-factors 2-levels (2-way between-subjects ANOVA)</h2>
<span class="anchor" id="line-174"></span><p class="line867">
<h3 id="FEAT_details-8">FEAT details</h3>
<span class="anchor" id="line-175"></span><p class="line867"><strong>Fixed Effects</strong> <span class="anchor" id="line-176"></span><span class="anchor" id="line-177"></span><p class="line867"><strong>Cell means.</strong> In this case there are 8 subjects and 2 factors (A/B), each with two levels.  The data are ordered: <tt class="backtick">A1B1</tt>, <tt class="backtick">A1B1</tt>, <tt class="backtick">A1B2</tt>, <tt class="backtick">A1B2</tt>, <tt class="backtick">A2B1</tt>, <tt class="backtick">A2B1</tt>, <tt class="backtick">A2B2</tt>, <tt class="backtick">A2B2</tt>.  We start with the cell means approach where each EV in the model is modeling the mean of a single cell, specifically EV1=mean(<tt class="backtick">A1B1</tt>), EV2=mean(<tt class="backtick">A1B2</tt>), etc.  Mean comparisons are straightforward to construct with this model, but the standard ANOVA F-tests take more thought.  These include: main A effect, main B effect and the interaction effect.  The main A effect tests whether mean(<tt class="backtick">A1</tt>)=mean(<tt class="backtick">A2</tt>).  In this case we average the <tt class="backtick">A1</tt> cells and <tt class="backtick">A2</tt> cells to get the contrast, [1 1 -1 -1], which is selected for an F-test.  Likewise the contrast for the main B effect is [1 -1 1 -1] and is selected for a separate F-test.  The interaction effect tests whether <tt class="backtick">A1B1</tt>-<tt class="backtick">A1B2</tt>=<tt class="backtick">A2B1</tt>-<tt class="backtick">A2B2</tt>, which is equivalent to <tt class="backtick">A1B1</tt>-<tt class="backtick">A1B2</tt>-<tt class="backtick">A2B1</tt>+<tt class="backtick">A2B2</tt>=0, corresponding to the [1 -1 -1 1] contrast, selected as a 3rd F-test. <span class="anchor" id="line-178"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_by_two_cell_means.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-179"></span><span class="anchor" id="line-180"></span><span class="anchor" id="line-181"></span><span class="anchor" id="line-182"></span><span class="anchor" id="line-183"></span><p class="line867"><strong>Factor effects approach.</strong>  As stated previously, the factor effects approach is equivalent to the cell means approach, but some of the contrasts may be more intuitive.  Following the rules state before, first determine how many EVs are required for each factor.  In this case there are two factors, each with 2 levels and so one EV is required to model each factor's main effect.  The interaction effect is constructed by multiplying these two EVs together, element-wise.  Starting with factor A, assign A1 as the reference level, so the A EV has a -1 for <tt class="backtick">A1</tt> and 1 for <tt class="backtick">A2</tt>.  Similarly, the B EB has a value of -1 for B1 and 1 for B2.  The interaction EV (3rd EV) is an element-wise product of the first 2 EVs.  Lastly is the column of 1s.  The F-test for the main A effect is simply and F-test that combines all individual contrasts for each A EV, in this case only the first.  Likewise for the main B effect.  The interaction effect, similarly, is an F-test on the interaction EV.  As described in the 1-factor 4-level ANOVA example, cell means can also be obtained from this model.  For example, multiplying the design matrix with the parameter vector, [PE1, PE2, PE3, PE4], yields -PE1-PE2+PE3+PE4 for all rows corresponding to <tt class="backtick">A1B1</tt> and so [-1 -1 1 1] is the contrast for <tt class="backtick">A1B1</tt>.  The other cell mean contrasts are displayed below. <span class="anchor" id="line-184"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_by_two_factor_eff.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-185"></span><span class="anchor" id="line-186"></span><span class="anchor" id="line-187"></span><span class="anchor" id="line-188"></span><span class="anchor" id="line-189"></span><p class="line867"><strong>Random Effects</strong> If both factors are random effects then the F-tests for the effects of the factors are different - the denominator in the F is derived from the interaction effect and not the within-cell errors. In this case, the relevant F images for factors A and B can be formed as Fa=fstat1/fstat3 and Fb=fstat2/fstat3. In order to carry this out, first run FEAT using the above design. Then: <span class="anchor" id="line-190"></span><span class="anchor" id="line-191"></span><p class="line867"><span class="anchor" id="line-192"></span><span class="anchor" id="line-193"></span><span class="anchor" id="line-194"></span><span class="anchor" id="line-195"></span><pre><span class="anchor" id="line-1-2"></span>cd &lt;featdir&gt;/stats
<span class="anchor" id="line-2"></span>fslmaths fstat1 -div fstat3 fstata`&lt;&lt;BR&gt;&gt; `fslmaths fstat2 -div fstat3 fstatb
<span class="anchor" id="line-3"></span>ftoz -zout zfstata fstata 1 1`&lt;&lt;BR&gt;&gt; `ftoz -zout zfstatb fstatb 1 1</pre><span class="anchor" id="line-196"></span><p class="line862">You could then do thresholding on zfstata and zfstatb with <tt class="backtick">easythresh</tt>. <span class="anchor" id="line-197"></span><span class="anchor" id="line-198"></span><p class="line867"><strong>Mixed Effects</strong> <span class="anchor" id="line-199"></span><span class="anchor" id="line-200"></span><p class="line874">If one factor is random and the other is fixed then we want a mixed effects analysis. In this case the fstat which needs the different denominator is the one associated with the fixed factor. For example, if factor A is fixed and factor B is random, then fstat2 already gives you the effect of factor B and for factor A you need to create Fa=fstat1/fstat3 as above. <span class="anchor" id="line-201"></span><span class="anchor" id="line-202"></span><p class="line867">
<h3 id="Randomise_details-8">Randomise details</h3>
<span class="anchor" id="line-203"></span><p class="line874">Either of the above models may also be used with randomise. <span class="anchor" id="line-204"></span><span class="anchor" id="line-205"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-206"></span><span class="anchor" id="line-207"></span><p class="line867">
<h2 id="ANOVA:_2-factors_2-_.26_3-levels_.282x3_between-subjects_ANOVA.29">ANOVA: 2-factors 2- &amp; 3-levels (2x3 between-subjects ANOVA)</h2>
<span class="anchor" id="line-208"></span><p class="line867">
<h3 id="FEAT_details-9">FEAT details</h3>
<span class="anchor" id="line-209"></span><p class="line867"><strong>Cell means.</strong> The design matrix setup is very similar to the previous example.  In this case there are 12 subjects, two in each AB level combination.  Factor A has 2 levels and B has 3 where the subjects are ordered all A1's, followed by A2, and then <tt class="backtick">B1</tt>, <tt class="backtick">B2</tt>, <tt class="backtick">B3</tt> within each level of A.  Each EV models a cell mean and since there are 6 cells, the model has 6 EVs.  To test the main A effect, the contrast comparing <tt class="backtick">A1</tt> to <tt class="backtick">A2</tt> is used.  In this case each level of A is spread across the three levels of B, so they would be combined in the [1 1 1 -1 -1 -1] contrast, to reflect <tt class="backtick">A1</tt>-<tt class="backtick">A2</tt>.  The first F-test is for the main A effect.  The main B effect will require 2 contrasts.  The null of the main B effect is that <tt class="backtick">B1</tt>=<tt class="backtick">B2</tt>=<tt class="backtick">B3</tt>, which simplifies to 0=<tt class="backtick">B2</tt>-<tt class="backtick">B1</tt>=<tt class="backtick">B3</tt>-<tt class="backtick">B1</tt>.  Therefore, the F-test for the main B effect uses both the B2-B1 and B3-B1 contrasts given by [-1 1 0 -1 1 0] and [-1 0 1 -1 0 1], respectively.  The interaction effect tests whether the <tt class="backtick">A1</tt>-<tt class="backtick">A2</tt> difference varies across levels of B.  In other words, <tt class="backtick">A1B1</tt>-<tt class="backtick">A2B1</tt>=<tt class="backtick">A1B2</tt>-<tt class="backtick">A2B2</tt>=<tt class="backtick">A1B3</tt>-<tt class="backtick">A2B3</tt>, which simplifies to <tt class="backtick">A1B1</tt>-<tt class="backtick">A2B1</tt>-<tt class="backtick">A1B3</tt>+<tt class="backtick">A2B3</tt>=<tt class="backtick">A1B2</tt>-<tt class="backtick">A2B2</tt>-<tt class="backtick">A1B3</tt>+<tt class="backtick">A2B3</tt>=0, and corresponds to simultaneously testing [1 0 -1 -1 0 1] and [0 1 -1 0 -1 1]. <span class="anchor" id="line-210"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/anova_2_3_cellmeans.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-211"></span><span class="anchor" id="line-212"></span><span class="anchor" id="line-213"></span><span class="anchor" id="line-214"></span><span class="anchor" id="line-215"></span><p class="line867"><strong>Factor effects approach.</strong>  We again follow the rules covered in the previous factor effects setups.  In this case A will have 1 EV and B will have 2 EVs to model the main effects for A and B.  Since B has 2 EVs (these are referred to as B-first and B-second in the figure), the AB interaction will comprise of 2 EVS, one formed through element-wise multiplication of the A EV with the first of the B EVs and the second is the A EV multiplied by the second B EV.  Specifically, A is modeled in the first EV, which takes on a value of -1 for <tt class="backtick">A1</tt> and 1 for <tt class="backtick">A2</tt>.  EV2 is the first of the B EVs and takes on a -1 for <tt class="backtick">B1</tt>, 1 for <tt class="backtick">B2</tt> and 0 for <tt class="backtick">B3</tt>.  EV3 is the second of the B EVs and takes on a -1 for <tt class="backtick">B1</tt>, 0 for <tt class="backtick">B2</tt> and -1 for <tt class="backtick">B3</tt>.  EV4 is an element-wise product of EVs 1&amp;2 and EV5 is an element-wise product of EVs 1&amp;3.  EV6 is the overall mean. <span class="anchor" id="line-216"></span><span class="anchor" id="line-217"></span><p class="line862">The contrasts for the main effects and interactions are much easier using this setup.  You start by setting up a contrast for each EV and the test for each effect is simply an F-test that selects the related contrasts.  For example, the main A effect is modeled solely through EV1, so only contrast 1 is selected in the F-test for A.  Since the main effect for B is modeled through EVs 2&amp;3, the corresponding contrasts (C2&amp;C3) are selected in the F-test for the main B effect.  Likewise for the interaction effect. <span class="anchor" id="line-218"></span><span class="anchor" id="line-219"></span><p class="line862">Lastly, as described in the 1-factor 4-level ANOVA example, cell means can also be obtained from this model.  For example, multiplying the design matrix with the parameter vector, [PE1, PE2, PE3, PE4, PE5, PE6], yields -PE1-PE2-PE3+PE4+PE5+PE6 for all rows corresponding to <tt class="backtick">A1B1</tt> and so [-1 -1 -1 1 1 1] is the contrast for <tt class="backtick">A1B1</tt>. <span class="anchor" id="line-220"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/anova_2_3_factor_eff.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-221"></span><span class="anchor" id="line-222"></span><span class="anchor" id="line-223"></span><span class="anchor" id="line-224"></span><span class="anchor" id="line-225"></span><p class="line867">
<h3 id="Randomise_details-9">Randomise details</h3>
<span class="anchor" id="line-226"></span><p class="line874">Either of the above models may also be used with randomise. <span class="anchor" id="line-227"></span><span class="anchor" id="line-228"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-229"></span><span class="anchor" id="line-230"></span><p class="line867">
<h2 id="ANOVA:_3-factors_2-levels_.283-way_between-subjects_ANOVA.29">ANOVA: 3-factors 2-levels (3-way between-subjects ANOVA)</h2>
<span class="anchor" id="line-231"></span><p class="line874">We have 16 subjects and 3 factors, each at 2 levels. <span class="anchor" id="line-232"></span><span class="anchor" id="line-233"></span><p class="line867">
<h3 id="FEAT_details-10">FEAT details</h3>
<span class="anchor" id="line-234"></span><p class="line867"><strong>Fixed Effects</strong> <tt class="backtick">Factor&nbsp;effects&nbsp;approach.</tt>  The cell means approach should be straightforward to set up, but the test for the 3-way interaction is quite difficult.  Therefore only the factor effects approach is described here.  Following the steps for setting up a factor effects model, it is first determined that each factor will require a single EV (as each factor has 2 levels).  In this case there will be 3 possible 2-way interactions and 1 3-way interaction.  EV1 takes on a value of -1 for A1 and 1 for A2.  EV2 does the same for B and EV3 does the same for C.  Creating interactions is done by simply multiplying the main effect EVs (first 3 EVs in this case) of interest together, element-wise.  For example, all 2 way interaction regressors are an element-wise product of the corresponding pair of EVs relating to the main effects. For the AB interaction, you would multiply the A EV with the B EV, element-wise, hence EV4 is the product of EVs 1 and 2.  Likewise EVs 5 and 6 are the AC and BC interactions.  For the 3-way interaction, you multiply together all main effect regressors, element-wise, and so the ABC 3-way interaction is the element-wise product of the first 3 EVs.  If the mean for the <tt class="backtick">A1B1C1</tt> cell was desired, the [-1 -1 -1 1 1 1 -1 1] contrast would be use.  Likewise for the other 5 cells of the ANOVA. <span class="anchor" id="line-235"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg9.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-236"></span><span class="anchor" id="line-237"></span><span class="anchor" id="line-238"></span><span class="anchor" id="line-239"></span><span class="anchor" id="line-240"></span><p class="line867"><strong>Random/Mixed Effects</strong> <span class="anchor" id="line-241"></span><span class="anchor" id="line-242"></span><p class="line874">The following table shows how to test for factor effects with various models: <span class="anchor" id="line-243"></span><div><table><tbody><tr>  <td><p class="line891"><strong>model</strong> </td>
  <td><p class="line891"><strong>A</strong> </td>
  <td><p class="line891"><strong>B</strong> </td>
  <td><p class="line891"><strong>C</strong> </td>
  <td><p class="line891"><strong>F(A)</strong> </td>
  <td><p class="line891"><strong>F(B)</strong> </td>
  <td><p class="line891"><strong>F(C)</strong> </td>
  <td><p class="line891"><strong>F(AB)</strong> </td>
  <td><p class="line891"><strong>F(AC)</strong> </td>
  <td><p class="line891"><strong>F(BC)</strong> </td>
  <td><p class="line891"><strong>F(ABC)</strong> </td>
</tr>
<tr>  <td><span class="anchor" id="line-244"></span><p class="line862">1 </td>
  <td><p class="line862">F </td>
  <td><p class="line862">F </td>
  <td><p class="line862">F </td>
  <td><p class="line862">fstat1 </td>
  <td><p class="line862">fstat2 </td>
  <td><p class="line862">fstat3 </td>
  <td><p class="line862">fstat4 </td>
  <td><p class="line862">fstat5 </td>
  <td><p class="line862">fstat6 </td>
  <td><p class="line862">fstat7 </td>
</tr>
<tr>  <td><span class="anchor" id="line-245"></span><p class="line862">2 </td>
  <td><p class="line862">R </td>
  <td><p class="line862">R </td>
  <td><p class="line862">R </td>
  <td><p class="line862"> </td>
  <td><p class="line862"> </td>
  <td><p class="line862"> </td>
  <td><p class="line862">fstat4/fstat7 </td>
  <td><p class="line862">fstat5/fstat7 </td>
  <td><p class="line862">fstat6/fstat7 </td>
  <td><p class="line862">fstat7 </td>
</tr>
<tr>  <td><span class="anchor" id="line-246"></span><p class="line862">3 </td>
  <td><p class="line862">F </td>
  <td><p class="line862">R </td>
  <td><p class="line862">R </td>
  <td><p class="line862"> </td>
  <td><p class="line862">fstat2/fstat6 </td>
  <td><p class="line862">fstat3/fstat6 </td>
  <td><p class="line862">fstat4/fstat7 </td>
  <td><p class="line862">fstat5/fstat7 </td>
  <td><p class="line862">fstat6 </td>
  <td><p class="line862">fstat7 </td>
</tr>
<tr>  <td><span class="anchor" id="line-247"></span><p class="line862">4 </td>
  <td><p class="line862">F </td>
  <td><p class="line862">F </td>
  <td><p class="line862">R </td>
  <td><p class="line862">fstat1/fstat5 </td>
  <td><p class="line862">fstat2/fstat6 </td>
  <td><p class="line862">fstat3 </td>
  <td><p class="line862">fstat4/fstat7 </td>
  <td><p class="line862">fstat5 </td>
  <td><p class="line862">fstat6 </td>
  <td><p class="line862">fstat7 </td>
</tr>
</tbody></table></div><span class="anchor" id="line-248"></span><span class="anchor" id="line-249"></span><span class="anchor" id="line-250"></span><span class="anchor" id="line-251"></span><span class="anchor" id="line-252"></span><p class="line867">
<h3 id="Randomise_details-10">Randomise details</h3>
<span class="anchor" id="line-253"></span><p class="line874">The the above model may also be used with randomise. <span class="anchor" id="line-254"></span><span class="anchor" id="line-255"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-256"></span><span class="anchor" id="line-257"></span><p class="line867">
<h1 id="Experimental_Designs_-_Repeated_measures">Experimental Designs - Repeated measures</h1>
<span class="anchor" id="line-258"></span><p class="line862">The standard GLM is appropriate for data with independent, identically distributed errors.  In short, this is any type of design where there is only one scan per subject. FEAT has the ability to accommodate independent data with heterogeneous variance (the mixture of common between subject variance and subject-varying measurement error noise), but cannot account for arbitrary repeated measures correlation.  Likewise, randomise cannot accommodate general repeated measures designs.  That said, there are several very <em>special cases</em> where the GLM (and Feat, and randomise) can model repeated measures, though usually with assumptions and caveats.  We detail these limitations in each example below. <span class="anchor" id="line-259"></span><span class="anchor" id="line-260"></span><p class="line867">
<h2 id="Single-Group_Paired_Difference_.28Paired_T-Test.29">Single-Group Paired Difference (Paired T-Test)</h2>
<span class="anchor" id="line-261"></span><p class="line862">This model is used when each subject has <em>exactly</em> 2 measures and the average difference between these two measures across subjects is of interest. In the example below there are 8 subjects, each with a measure before and after treatment (runA and runB, respectively) and the hypothesis is whether the average difference of runA-runB is different than 0. <span class="anchor" id="line-262"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="{i}" height="16" src="/fsl/wiki_static/fsl/img/icon-info.png" title="{i}" width="16" /> <strong>Statistics Jargon Decoder: Repeated Measures ANOVA (1).</strong>  Note that this is the simplest possible "Repeated Measures ANOVA", where there are two factors, one fixed, one random.  The fixed factor has two levels, "pre" and "post", or "condition 1" and "condition 2".  The random factor is subject; each subject has a random intercept (average) which we model with the N<sub>subject</sub> <em>dummy</em> or indicator variables.  As this is a balanced design (we don't consider subjects missing one or the other scan), the inferences are valid and should be equivalent to those obtained with an mixed effects inference program, like R's <tt class="backtick">lmer</tt> or SAS's <tt class="backtick">proc_mixed</tt>. </td>
</tr>
</tbody></table></div><span class="anchor" id="line-263"></span><span class="anchor" id="line-264"></span><span class="anchor" id="line-265"></span><span class="anchor" id="line-266"></span><span class="anchor" id="line-267"></span><p class="line867">
<h3 id="FEAT_details-11">FEAT details</h3>
<span class="anchor" id="line-268"></span><p class="line862">Make sure that the subjects are in the same order within each group of 8! We need one EV for the A-B differences, and then one extra EV for each subject, making 9 in all. EVs 2-9 model each subject's mean effect - in this analysis this is a confound, i.e. parameter estimates 2-9 are ignored, but without this part of the model, the mean effects would intefere with the estimation of the A-B paired differences. A contrast with a one for EV1 and zeros elsewhere tests for A-B paired differences. Significance of C1 implies A&gt;B and significance of C2 implies B&gt;A.  Inferences should not be carried out using contrasts that incorporate any of the subject mean effect regressors (EVs 2-9). <span class="anchor" id="line-269"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg3.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-270"></span><span class="anchor" id="line-271"></span><span class="anchor" id="line-272"></span><span class="anchor" id="line-273"></span><span class="anchor" id="line-274"></span><p class="line867">
<h3 id="Randomise_details-11">Randomise details</h3>
<span class="anchor" id="line-275"></span><p class="line874">For the paired t-test, randomise requires a special type of permutation and the most fool-proof way to ensure the test is carried out correctly is to manually compute the differences between runA and runB for each subject and then enter these values into a 1-sample t-test. <span class="anchor" id="line-276"></span><span class="anchor" id="line-277"></span><p class="line874">As an example, assume that there are 16 separate 3D brain images (for each of the 2 runs for each of the 8 subjects). Start by using fslmaths to compute the difference between runA and runB for each subject and then use fslmerge to create a single 4D volume with 8 images (along the 4th dimension).  If working with fMRI, be sure to work with cope and not tstat images. <span class="anchor" id="line-278"></span><span class="anchor" id="line-279"></span><p class="line867"><span class="anchor" id="line-280"></span><span class="anchor" id="line-281"></span><span class="anchor" id="line-282"></span><span class="anchor" id="line-283"></span><span class="anchor" id="line-284"></span><pre><span class="anchor" id="line-1-3"></span>fslmaths subject1_rA -sub subject1_rB sub1_diff
<span class="anchor" id="line-2-1"></span>fslmaths subject2_rA -sub subject2_rB sub2_diff
<span class="anchor" id="line-3-1"></span>(repeat for subjects 3-8)
<span class="anchor" id="line-4"></span>fslmerge -t runA_minus_runB sub1_diff sub2_diff sub3_diff sub4_diff sub5_diff sub6_diff sub7_diff sub8_diff</pre><span class="anchor" id="line-285"></span><p class="line862">The resulting 4D volume (i.e. <tt class="backtick">runA_minus_runB</tt>) can then be used as the input for the 1-sample t-test, as described above. <span class="anchor" id="line-286"></span><span class="anchor" id="line-287"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-288"></span><span class="anchor" id="line-289"></span><p class="line867">
<h2 id="Single-Group.2C_Three_Measurements_.28.22Tripled_T-Test.22.29">Single-Group, Three Measurements ("Tripled T-Test")</h2>
<span class="anchor" id="line-290"></span><p class="line874">This model is similar to the paired t-test, but instead of 2 measures per subject there are exactly 3 measures per subject. <span class="anchor" id="line-291"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="{i}" height="16" src="/fsl/wiki_static/fsl/img/icon-info.png" title="{i}" width="16" /> <strong>Statistics Jargon Decoder: Repeated Measures ANOVA (2).</strong>  This is again a "Repeated Measures ANOVA" with one fixed and one random factor, the same as the previous example except that the fixed factor has three levels.  Fitting such a mixed effects model with Ordinary Least Squares (OLS) (as done in Feat) requires an assumption of <em>compound symmetry</em>.  This is the state of equal variance and intra-subject correlations being equal.  That is, Cov(scan1,scan2) = Cov(scan1,scan3) = Cov(scan2,scan3). </td>
</tr>
</tbody></table></div><span class="anchor" id="line-292"></span><span class="anchor" id="line-293"></span><span class="anchor" id="line-294"></span><span class="anchor" id="line-295"></span><span class="anchor" id="line-296"></span><p class="line862">The assumption of this design, compound symmetry, is probably a reasonable assumption unless, say, the data are from a long or irregularly sampled longitudinal study.  For example, if scan 1 and 2 are collected 1 week apart and scan 3 is collected 1 year later, it's unlikely that they are equally correlated.  Note, also, only intrasubject contrasts are valid with this design. For example, a [1 1 1] contrast cannot be assessed; if such a contrast is of interest, the individual measures should be averaged with <tt class="backtick">fslmaths</tt> and then studied in a one-sample t-test (assuming they are difference measures, and can be so suitably analysed). <span class="anchor" id="line-297"></span><span class="anchor" id="line-298"></span><p class="line867">
<h3 id="FEAT_details-12">FEAT details</h3>
<span class="anchor" id="line-299"></span><p class="line874">This is a natural extension of the paired t-test, but the contrasts are slightly counter-intuitive so we explain this case in detail. We have 5 subjects, each scanned under 3 conditions, A, B and C. We enter the 5 condition A scans first, then 5 B and then 5 C. As with the paired t-test, EVs 3-7 simply remove the subject means and are not used in the contrasts. <span class="anchor" id="line-300"></span><span class="anchor" id="line-301"></span><p class="line874">We now want to form the 3 contrasts A-B, A-C and B-C. Note that, somewhat surprisingly, A-B is not given by [1 0 0...]! We define PE1=a and PE2=b. Then, we can see by looking at the three condition blocks, that the mean (on top of the global mean taken out by EVs 3-7) of condition A is modelled by A=a+b. Likewise, B=-a, and C=-b (look at the values in EVs 1 and 2). Therefore we have A-B = 2a+b = contrast [ 2 1 0....], and A-C = a+2b = contrast [ 1 2 0....], and B-C = -a+b = contrast [ -1 1 0....]. <span class="anchor" id="line-302"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg3b.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-303"></span><span class="anchor" id="line-304"></span><span class="anchor" id="line-305"></span><span class="anchor" id="line-306"></span><span class="anchor" id="line-307"></span><p class="line867">
<h3 id="Randomise_details-12">Randomise details</h3>
<span class="anchor" id="line-308"></span><p class="line874">It is not possible to model 3 paired differences in a single model using Randomise. Follow the Paired T-Test instructions to run the 3 separate paired T-Tests. <span class="anchor" id="line-309"></span><span class="anchor" id="line-310"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-311"></span><span class="anchor" id="line-312"></span><p class="line867">
<h2 id="Multi-Session_.26_Multi-Subject_.28Repeated_Measures_-_Three_Level_Analysis.29">Multi-Session &amp; Multi-Subject (Repeated Measures - Three Level Analysis)</h2>
<span class="anchor" id="line-313"></span><p class="line867">
<h3 id="FEAT_details-13">FEAT details</h3>
<span class="anchor" id="line-314"></span><p class="line874">5 subjects each have three sessions. For the reasons described above, we will combine across sessions to create COPEs for the subject means of each subject, using a fixed-effects analysis. In the stats GUI, we select Fixed effects. Then we setup the second-level analysis with 5 EVs, where each EV picks out the 3 sessions that correspond to a particular subject. We also need 5 contrasts to represent the 5 subject means, as follows: <span class="anchor" id="line-315"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg4a.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-316"></span><span class="anchor" id="line-317"></span><span class="anchor" id="line-318"></span><span class="anchor" id="line-319"></span><span class="anchor" id="line-320"></span><p class="line862">Now we want the mean group effect, across subjects, achieved with a third-level <strong>ME</strong> analysis. Select <strong>Inputs are lower-level FEAT directories</strong> and select the 5 relevant directories created at second-level, named something like subject_N.gfeat/cope1.feat. <span class="anchor" id="line-321"></span><div><table><tbody><tr>  <td><p class="line862"> <img align="left" alt="basis functions" class="attachment" src="attachments/FEAT(2f)UserGuide/eg4b.png" title="basis functions" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-322"></span><span class="anchor" id="line-323"></span><span class="anchor" id="line-324"></span><span class="anchor" id="line-325"></span><span class="anchor" id="line-326"></span><p class="line867">
<h3 id="Randomise_details-13">Randomise details</h3>
<span class="anchor" id="line-327"></span><p class="line862">If there are multiple measures per subject in a randomise analysis, the second level model, averaging the measures within subject, is carried out using <tt class="backtick">fslmerge</tt>/<tt class="backtick">fslmaths</tt>.  For example, if sub1_a.nii.gz, sub1_b.nii.gz, sub2_c.nii.gz are three images corresponding to 3 sessions for subject 1, use the following: <span class="anchor" id="line-328"></span><span class="anchor" id="line-329"></span><p class="line867"><span class="anchor" id="line-330"></span><span class="anchor" id="line-331"></span><span class="anchor" id="line-332"></span><pre><span class="anchor" id="line-1-4"></span>fslmerge -t sub1_all sub1_a sub1_b sub1_c
<span class="anchor" id="line-2-2"></span>fslmaths sub1_all -Tmean sub1_avg</pre><span class="anchor" id="line-333"></span><p class="line862">To find the mean group effect, the individual subject averages are combined using <tt class="backtick">fslmerge</tt> and the resulting 4D file would be used in a <a href="./GLM.html#Single-Group_Average_.28One-Sample_T-Test.29">Single Group Average analysis</a> above. <span class="anchor" id="line-334"></span><span class="anchor" id="line-335"></span><p class="line867"><span class="anchor" id="line-336"></span><span class="anchor" id="line-337"></span><pre><span class="anchor" id="line-1-5"></span>fslmerge -t all_subs_avg sub1_avg sub2_avg sub3_avg sub4_avg sub5_avg</pre><span class="anchor" id="line-338"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-339"></span><span class="anchor" id="line-340"></span><p class="line867">
<h2 id="ANOVA:_2-groups.2C_2-levels_per_subject_.282-way_Mixed_Effect_ANOVA.29">ANOVA: 2-groups, 2-levels per subject (2-way Mixed Effect ANOVA)</h2>
<span class="anchor" id="line-341"></span><p class="line874">We now have 4 subjects each of whom have 2 measures, for a total of 8 observations.  Additionally the subjects are split into 2 groups of 2. <span class="anchor" id="line-342"></span><span class="anchor" id="line-343"></span><p class="line867">
<h3 id="FEAT_details-14">FEAT details</h3>
<span class="anchor" id="line-344"></span><p class="line874">As mentioned earlier, the GLM is not designed to handle repeated measures, although if each subject has complete data (both measures), it is possible to model this using the GLM under the assumption that the covariance between measures within-subject follows a compound symmetric structure.  Do not use this model unless all subjects have complete data.  As you may notice, this design setup resembles the factor-effects setup (see 2-factors 2-levels setup above).  The only difference is the column of 1's is replaced with EVs to model the means for each subject and the EV that would normally be included to model group (-1 for group1 and 1 for group 2) has been omitted as it would cause a rank-deficiency with the EVs modeling the subject-specific means.  It is not possible to look at group differences in this model as subject is treated as a random effect.  To do so, average the 2 measures within-subject and run a 2 group mean comparison on these data in a 3 level analysis approach.  Otherwise, the main effect for level is given by C1 and C2 tests the interaction of group and the other factor. <span class="anchor" id="line-345"></span><div><table><tbody><tr>  <td><p class="line862"> <img alt="align=&quot;left&quot;" class="attachment" src="attachments/GLM/two_grp_two_lev.png" title="align=&quot;left&quot;" width="900" /> </td>
</tr>
</tbody></table></div><span class="anchor" id="line-346"></span><span class="anchor" id="line-347"></span><span class="anchor" id="line-348"></span><span class="anchor" id="line-349"></span><span class="anchor" id="line-350"></span><p class="line867">
<h3 id="Randomise_details-14">Randomise details</h3>
<span class="anchor" id="line-351"></span><p class="line862">Due to how the data would need to be permuted, the FEAT model may not be used in randomise.  Instead, just as in the paired t-test example, paired differences within-subject would be computed via <tt class="backtick">fslmaths</tt> and a <a href="./GLM.html#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29">two-sample t-test</a> could be used to test whether the run1-run2 difference differed between the two groups. <span class="anchor" id="line-352"></span><span class="anchor" id="line-353"></span><p class="line867"><hr /><p class="line874"> <span class="anchor" id="line-354"></span><span class="anchor" id="bottom"></span></div>
</div>
<hr>
2014-07-08 15:34
</body>
</html>
